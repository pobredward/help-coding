{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02b5bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Frozen Lake v1 환경 생성\n",
    "env = gym.make('FrozenLake-v1')\n",
    "\n",
    "# Q-table 초기화\n",
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "Q = np.zeros((n_states, n_actions))\n",
    "rewardList = []\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.1\n",
    "discount_rate = 1\n",
    "n_episodes = 10000\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "# epsilon-greedy 정책 설정\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.001\n",
    "\n",
    "# 상태를 이산적인 값으로 변환하는 함수\n",
    "def state_to_id(state):\n",
    "    if isinstance(state, tuple):\n",
    "        return state[0]\n",
    "    else:\n",
    "        return state\n",
    "\n",
    "# Q-learning 알고리즘\n",
    "for episode in range(n_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    rewardAll = 0\n",
    "    \n",
    "#     print(\"=========================\")\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        \n",
    "        state = state_to_id(state)\n",
    "        \n",
    "        # epsilon-greedy 정책에 따라 행동 선택\n",
    "        tradeoff = np.random.uniform(0, 1)\n",
    "        if tradeoff > epsilon:\n",
    "            action = np.argmax(Q[state, :])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        # 다음 상태, 보상, 종료 여부, 디버깅 정보 얻기\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        next_state = state_to_id(next_state)\n",
    "        \n",
    "        # Q-value 업데이트\n",
    "        Q[state, action] = Q[state, action] + learning_rate * (reward + discount_rate * np.max(Q[next_state, :]) - Q[state, action])\n",
    "        rewardAll += reward\n",
    "        \n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "        \n",
    "        # 종료 조건 검사\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # epsilon 값 감소\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "    \n",
    "    rewardList.append(rewardAll)\n",
    "#     print(\"rewardList: \", rewardList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d9452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.091\n"
     ]
    }
   ],
   "source": [
    "print(\"Score over time: \" +  str(sum(rewardList)/n_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50568caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table Values\n",
      "[[0.85001054 0.85009794 0.85050774 0.85094246]\n",
      " [0.67215863 0.54235065 0.61307163 0.85094246]\n",
      " [0.77616504 0.78202914 0.76090475 0.85094246]\n",
      " [0.58274651 0.4578615  0.59908161 0.85094246]\n",
      " [0.8507561  0.40146677 0.57331867 0.6233718 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.28882991 0.16786912 0.56583466 0.24443381]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.34755305 0.35244301 0.41652659 0.84854266]\n",
      " [0.53276806 0.84311418 0.53103778 0.56417284]\n",
      " [0.74153354 0.4968292  0.46482119 0.46835505]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.44121911 0.60657034 0.89034436 0.44420459]\n",
      " [0.83863998 0.92670663 0.88953587 0.88174504]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Q-Table Values\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b0e54",
   "metadata": {},
   "source": [
    "### 최적의 정책 구하기 및 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f80c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy:\n",
      "[[3. 3. 3. 3.]\n",
      " [0. 0. 2. 0.]\n",
      " [3. 1. 0. 0.]\n",
      " [0. 2. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최적의 정책 구하기\n",
    "policy = np.zeros(n_states)\n",
    "for state in range(n_states):\n",
    "    policy[state] = np.argmax(Q[state, :])\n",
    "\n",
    "# 최적의 정책 출력\n",
    "print(\"Optimal policy:\")\n",
    "print(policy.reshape(4,4))\n",
    "\n",
    "# 화살표로 나타내기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Q-table에서 각 상태에서 최대 Q-value를 갖는 행동을 알아냄\n",
    "max_actions = np.argmax(Q, axis=1)\n",
    "\n",
    "# 각 상태에 화살표로 나타냄\n",
    "plt.imshow(np.zeros((4,4)), cmap='gray', vmin=0, vmax=1)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if max_actions[i*4+j] == 0:  # up\n",
    "            plt.arrow(j+0.5, i+0.9, 0, -0.7, head_width=0.2, head_length=0.1, fc='r', ec='r')\n",
    "        elif max_actions[i*4+j] == 1:  # right\n",
    "            plt.arrow(j+0.1, i+0.5, 0.7, 0, head_width=0.2, head_length=0.1, fc='r', ec='r')\n",
    "        elif max_actions[i*4+j] == 2:  # down\n",
    "            plt.arrow(j+0.5, i+0.1, 0, 0.7, head_width=0.2, head_length=0.1, fc='r', ec='r')\n",
    "        elif max_actions[i*4+j] == 3:  # left\n",
    "            plt.arrow(j+0.9, i+0.5, -0.7, 0, head_width=0.2, head_length=0.1, fc='r', ec='r')\n",
    "plt.xlim(0, 4)\n",
    "plt.ylim(0, 4)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cc870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
